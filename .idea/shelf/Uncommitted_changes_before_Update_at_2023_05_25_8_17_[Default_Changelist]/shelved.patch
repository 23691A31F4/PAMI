Index: PAMI/AssociationRules/basic/ARWithConfidence.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from PAMI.AssociationRules.basic import abstract as _ab\n\n\nclass Confidence:\n\n    def __init__(self, patterns, singleItems, threshold):\n        \"\"\"\n        :param inputFile: input file name or path\n        :type inputFile: str\n        :param sep:\n        \"\"\"\n        self._frequentPatterns = patterns\n        self._singleItems = singleItems\n        self._threshold = threshold\n        self._finalPatterns = {}\n\n    def _generation(self, prefix, suffix):\n        if len(suffix) == 1:\n            conf = self._generaeWithConfidence(prefix, suffix[0])\n        for i in range(len(suffix)):\n            suffix1 = suffix[:i] + suffix[i + 1:]\n            prefix1 = prefix + ' ' + suffix[i]\n            for j in range(i + 1, len(suffix)):\n                self._generaeWithConfidence(prefix + ' ' + suffix[i], suffix[j])\n                # self._generation(prefix+ ' ' +suffix[i], suffix[i+1:])\n            self._generation(prefix1, suffix1)\n\n    def _generaeWithConfidence(self, lhs, rhs):\n        s = lhs + '\\t' + rhs\n        if self._frequentPatterns.get(s) == None:\n            return 0\n        minimum = self._frequentPatterns[s]\n        conflhs = minimum / self._frequentPatterns[lhs]\n        confrhs = minimum / self._frequentPatterns[rhs]\n        if conflhs >= self._threshold:\n            s1 = lhs + '->' + rhs\n            self._finalPatterns[s1] = conflhs\n        if confrhs >= self._threshold:\n            s1 = rhs + '->' + lhs\n            self._finalPatterns[s1] = confrhs\n\n    def run(self):\n        for i in range(len(self._singleItems)):\n            suffix = self._singleItems[:i] + self._singleItems[i + 1:]\n            prefix = self._singleItems[i]\n            for j in range(i + 1, len(self._singleItems)):\n                self._generaeWithConfidence(self._singleItems[i], self._singleItems[j])\n            self._generation(prefix, suffix)\n\n\nclass ARWithConfidence:\n    \"\"\"\n    temporalDatabaseStats is class to get stats of database.\n        Attributes:\n        ----------\n        frequentPattern : list or dict\n            list\n        measure: condition to calculate the strength of rule\n            str\n        threshold: condition to satisfy\n            int\n        Methods:\n        -------\n        startMine()\n    \"\"\"\n\n    def __init__(self, iFile, threshold, sep):\n        \"\"\"\n        :param inputFile: input file name or path\n        :type inputFile: str\n        :param sep:\n        \"\"\"\n        self._iFile = iFile\n        self._threshold = threshold\n        self._finalPatterns = {}\n        self._sep = sep\n\n    def _readPatterns(self):\n        self._frequentPatterns = {}\n        k = []\n        if isinstance(self._iFile, _ab._pd.DataFrame):\n            pattern, sup = [], []\n            if self._iFile.empty:\n                print(\"its empty..\")\n            i = self._iFile.columns.values.tolist()\n            if 'pattern' in i:\n                pattern = self._iFile['pattern'].tolist()\n            if 'support' in i:\n                support = self._iFile['support'].tolist()\n            for i in range(len(pattern)):\n                s = '\\t'.join(pattern[i])\n                self._frequentPattern[s] = support[i]\n        if isinstance(self._iFile, str):\n            if _ab._validators.url(self._iFile):\n                data = _ab._urlopen(self._iFile)\n                for line in data:\n                    line = line.strip()\n                    line = line.split(':')\n                    s = line[0].split(self._sep)\n                    s = '\\t'.join(s)\n                    self._frequentPatterns[s.strip()] = int(line[1])\n            else:\n                try:\n                    with open(self._iFile, 'r', encoding='utf-8') as f:\n                        for line in f:\n                            line = line.strip()\n                            line = line.split(':')\n                            s = line[0].split(self._sep)\n                            for j in s:\n                                if j not in k:\n                                    k.append(j)\n                            s = '\\t'.join(s)\n                            self._frequentPatterns[s.strip()] = int(line[1])\n                except IOError:\n                    print(\"File Not Found\")\n                    quit()\n        return k\n\n    def startMine(self):\n        self._startTime = _ab._time.time()\n        k = self._readPatterns()\n        a = Confidence(self._frequentPatterns, k, self._threshold)\n        a.run()\n        self._finalPatterns = a._finalPatterns\n        self._endTime = _ab._time.time()\n        process = _ab._psutil.Process(_ab._os.getpid())\n        self._memoryUSS = float()\n        self._memoryRSS = float()\n        self._memoryUSS = process.memory_full_info().uss\n        self._memoryRSS = process.memory_info().rss\n        print(\"Association rules successfully  generated from frequent patterns \")\n\n    def getMemoryUSS(self):\n        \"\"\"Total amount of USS memory consumed by the mining process will be retrieved from this function\n        :return: returning USS memory consumed by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self._memoryUSS\n\n    def getMemoryRSS(self):\n        \"\"\"Total amount of RSS memory consumed by the mining process will be retrieved from this function\n        :return: returning RSS memory consumed by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self._memoryRSS\n\n    def getRuntime(self):\n        \"\"\"Calculating the total amount of runtime taken by the mining process\n        :return: returning total amount of runtime taken by the mining process\n        :rtype: float\n        \"\"\"\n\n        return self._endTime - self._startTime\n\n    def getPatternsAsDataFrame(self):\n        \"\"\"Storing final frequent patterns in a dataframe\n        :return: returning frequent patterns in a dataframe\n        :rtype: pd.DataFrame\n        \"\"\"\n\n        dataFrame = {}\n        data = []\n        for a, b in self._finalPatterns.items():\n            data.append([a.replace('\\t', ' '), b])\n            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])\n        # dataFrame = dataFrame.replace(r'\\r+|\\n+|\\t+',' ', regex=True)\n        return dataFrame\n\n    def save(self, outFile):\n        \"\"\"Complete set of frequent patterns will be loaded in to a output file\n        :param outFile: name of the output file\n        :type outFile: file\n        \"\"\"\n        self._oFile = outFile\n        writer = open(self._oFile, 'w+')\n        for x, y in self._finalPatterns.items():\n            s1 = x.strip() + \":\" + str(y)\n            writer.write(\"%s \\n\" % s1)\n\n    def getPatterns(self):\n        \"\"\" Function to send the set of frequent patterns after completion of the mining process\n        :return: returning frequent patterns\n        :rtype: dict\n        \"\"\"\n        return self._finalPatterns\n\n    def printResults(self):\n        print(\"Total number of Association Rules:\", len(self.getPatterns()))\n        print(\"Total Memory in USS:\", self.getMemoryUSS())\n        print(\"Total Memory in RSS\", self.getMemoryRSS())\n        print(\"Total ExecutionTime in ms:\", self.getRuntime())\n\n\nif __name__ == \"__main__\":\n    _ap = str()\n    if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:\n        if len(_ab._sys.argv) == 5:\n            _ap = ARWithConfidence(_ab._sys.argv[1], _ab._sys.argv[3], float(_ab._sys.argv[4]))\n        if len(_ab._sys.argv) == 4:\n            _ap = ARWithConfidence(_ab._sys.argv[1], _ab._sys.argv[3])\n        _ap.startMine()\n        print(\"Total number of Association Rules:\", len(_ap.getPatterns()))\n        _ap.save(_ab._sys.argv[2])\n        print(\"Total Memory in USS:\", _ap.getMemoryUSS())\n        print(\"Total Memory in RSS\", _ap.getMemoryRSS())\n        print(\"Total ExecutionTime in ms:\", _ap.getRuntime())\n    else:\n        _ap = ARWithConfidence('patterns.txt', 0.8, '\\t')\n        _ap.startMine()\n        _ap.save('output.txt')\n        _ap.printResults()\n        print(\"Error! The number of input parameters do not match the total number of parameters provided\")
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/AssociationRules/basic/ARWithConfidence.py b/PAMI/AssociationRules/basic/ARWithConfidence.py
--- a/PAMI/AssociationRules/basic/ARWithConfidence.py	(revision d8a6a5bd0a669ec72f78315a4a363c33217c0be4)
+++ b/PAMI/AssociationRules/basic/ARWithConfidence.py	(date 1680663976528)
@@ -40,9 +40,13 @@
             self._finalPatterns[s1] = confrhs
 
     def run(self):
+        # for i in self._frequentPatterns:
+        #     if len(i) >= 2:
+        #         self._generaeWithConfidence()
         for i in range(len(self._singleItems)):
             suffix = self._singleItems[:i] + self._singleItems[i + 1:]
             prefix = self._singleItems[i]
+            #print(suffix, prefix)
             for j in range(i + 1, len(self._singleItems)):
                 self._generaeWithConfidence(self._singleItems[i], self._singleItems[j])
             self._generation(prefix, suffix)
@@ -106,9 +110,10 @@
                             line = line.strip()
                             line = line.split(':')
                             s = line[0].split(self._sep)
-                            for j in s:
-                                if j not in k:
-                                    k.append(j)
+                            if len(s) >= 2:
+                                for j in s:
+                                    if j not in k:
+                                        k.append(j)
                             s = '\t'.join(s)
                             self._frequentPatterns[s.strip()] = int(line[1])
                 except IOError:
@@ -119,6 +124,7 @@
     def startMine(self):
         self._startTime = _ab._time.time()
         k = self._readPatterns()
+        print(len(k))
         a = Confidence(self._frequentPatterns, k, self._threshold)
         a.run()
         self._finalPatterns = a._finalPatterns
Index: PAMI/episodeMining/EMMA.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/episodeMining/EMMA.py b/PAMI/episodeMining/EMMA.py
new file mode 100644
--- /dev/null	(date 1680660481683)
+++ b/PAMI/episodeMining/EMMA.py	(date 1680660481683)
@@ -0,0 +1,365 @@
+#  Copyright (C)  2021 Rage Uday Kiran
+#
+#      This program is free software: you can redistribute it and/or modify
+#      it under the terms of the GNU General Public License as published by
+#      the Free Software Foundation, either version 3 of the License, or
+#      (at your option) any later version.
+#
+#      This program is distributed in the hope that it will be useful,
+#      but WITHOUT ANY WARRANTY; without even the implied warranty of
+#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+#      GNU General Public License for more details.
+#
+#      You should have received a copy of the GNU General Public License
+#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+
+import abstract as _ab
+
+
+class Apriori(_ab._frequentEpisodes):
+    """
+        Apriori is one of the fundamental algorithm to discover frequent patterns in a transactional database.
+        This program employs apriori property (or downward closure property) to  reduce the search space effectively.
+        This algorithm employs breadth-first search technique to find the complete set of frequent patterns in a
+        transactional database.
+
+        Reference:
+        ----------
+            Agrawal, R., Imieli ́nski, T., Swami, A.: Mining association rules between sets of items in large databases.
+            In: SIGMOD. pp. 207–216 (1993), https://doi.org/10.1145/170035.170072
+
+
+        Attributes:
+        ----------
+            iFile : str
+                Input file name or path of the input file
+            oFile : str
+                Name of the output file or the path of output file
+            minSup: float or int or str
+                The user can specify minSup either in count or proportion of database size.
+                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+                Otherwise, it will be treated as float.
+                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+            sep : str
+                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+                However, the users can override their default separator.
+            startTime:float
+                To record the start time of the mining process
+            endTime:float
+                To record the completion time of the mining process
+            finalPatterns: dict
+                Storing the complete set of patterns in a dictionary variable
+            memoryUSS : float
+                To store the total amount of USS memory consumed by the program
+            memoryRSS : float
+                To store the total amount of RSS memory consumed by the program
+            Database : list
+                To store the transactions of a database in list
+
+        Methods:
+        -------
+            startMine()
+                Mining process will start from here
+            getPatterns()
+                Complete set of patterns will be retrieved with this function
+            save(oFile)
+                Complete set of frequent patterns will be loaded in to a output file
+            getPatternsAsDataFrame()
+                Complete set of frequent patterns will be loaded in to a dataframe
+            getMemoryUSS()
+                Total amount of USS memory consumed by the mining process will be retrieved from this function
+            getMemoryRSS()
+                Total amount of RSS memory consumed by the mining process will be retrieved from this function
+            getRuntime()
+                Total amount of runtime taken by the mining process will be retrieved from this function
+            candidateToFrequent(candidateList)
+                Generates frequent patterns from the candidate patterns
+            frequentToCandidate(frequentList, length)
+                Generates candidate patterns from the frequent patterns
+
+
+        Executing the code on terminal:
+        -------------------------------
+
+            Format:
+            ------
+                python3 Apriori.py <inputFile> <outputFile> <minSup>
+
+            Examples:
+            ---------
+                python3 Apriori.py sampleDB.txt patterns.txt 10.0   (minSup will be considered in times of minSup and count of database transactions)
+
+                python3 Apriori.py sampleDB.txt patterns.txt 10     (minSup will be considered in support count or frequency)
+
+
+        Sample run of the importing code:
+        ---------------------------------
+
+            import PAMI.frequentPattern.basic.Apriori as alg
+
+            obj = alg.Apriori(iFile, minSup)
+
+            obj.startMine()
+
+            frequentPatterns = obj.getPatterns()
+
+            print("Total number of Frequent Patterns:", len(frequentPatterns))
+
+            obj.save(oFile)
+
+            Df = obj.getPatternInDataFrame()
+
+            memUSS = obj.getMemoryUSS()
+
+            print("Total Memory in USS:", memUSS)
+
+            memRSS = obj.getMemoryRSS()
+
+            print("Total Memory in RSS", memRSS)
+
+            run = obj.getRuntime()
+
+            print("Total ExecutionTime in seconds:", run)
+
+        Credits:
+        --------
+            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+
+    """
+
+    _minSup = float()
+    _winLen = int()
+    _startTime = float()
+    _endTime = float()
+    _finalPatterns = {}
+    _iFile = " "
+    _oFile = " "
+    _sep = " "
+    _memoryUSS = float()
+    _memoryRSS = float()
+    _Database = []
+
+    def _creatingItemSets(self):
+        """
+            Storing the complete transactions of the database/input file in a database variable
+
+
+        """
+        self._Database = []
+        if isinstance(self._iFile, _ab._pd.DataFrame):
+            temp = []
+            if self._iFile.empty:
+                print("its empty..")
+            i = self._iFile.columns.values.tolist()
+            if 'Transactions' in i:
+                temp = self._iFile['Transactions'].tolist()
+
+            for k in temp:
+                self._Database.append(set(k))
+        if isinstance(self._iFile, str):
+            if _ab._validators.url(self._iFile):
+                data = _ab._urlopen(self._iFile)
+                for line in data:
+                    line.strip()
+                    line = line.decode("utf-8")
+                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp = [x for x in temp if x]
+                    self._Database.append(set(temp))
+            else:
+                try:
+                    with open(self._iFile, 'r', encoding='utf-8') as f:
+                        for line in f:
+                            line.strip()
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            self._Database.append(temp)
+                except IOError:
+                    print("File Not Found")
+                    quit()
+
+    def _convert(self, value):
+        """
+        To convert the user specified minSup value
+
+        :param value: user specified minSup value
+
+        :return: converted type
+        """
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = (len(self._Database) * value)
+        if type(value) is str:
+            if '.' in value:
+                value = float(value)
+                value = (len(self._Database) * value)
+            else:
+                value = int(value)
+        return value
+
+    def _calculateOneLength(self):
+        _tids = {}
+        for i in self._Database:
+            for j in i[1:]:
+                if j not in _tids:
+                    _tids[j] = {int(i[0])}
+                else:
+                    _tids[j].add(int(i[0]))
+        self._finalPatterns = {k: v for k, v in _tids.items() if len(v) >= self._minSup}
+
+    def _generateEvents(self, unifiedSet):
+        print(unifiedSet)
+
+    def _generateSamePatterns(self, candidateFrequent):
+        new_freqList = []
+        for i in range(0, len(candidateFrequent)):
+            item1 = candidateFrequent[i]
+            i1_list = item1.split()
+            for j in range(i + 1, len(candidateFrequent)):
+                item2 = candidateFrequent[j]
+                i2_list = item2.split()
+                if i1_list[:-1] == i2_list[:-1]:
+                    interSet = self._finalPatterns[item1].intersection(self._finalPatterns[item2])
+                    if len(interSet) >= self._minSup:
+                        newKey = item1 + "\t" + i2_list[-1]
+                        self._finalPatterns[newKey] = [interSet]
+                        new_freqList.append(newKey)
+                else:
+                    break
+
+        if len(new_freqList) > 0:
+            self._generateSamePatterns(new_freqList)
+
+    def _savePattern(self, prefix, suffix):
+        res = prefix + suffix
+        count = 0
+        for i in self._Database:
+                if set(res).issubset(i):
+                    count += 1
+        if count >= self._minSup:
+            self._finalPatterns[tuple(res)] = count
+
+    def startMine(self):
+        """
+            Frequent pattern mining process will start from here
+        """
+        self._Database = []
+        self._startTime = _ab._time.time()
+        self._creatingItemSets()
+        self._minSup = self._convert(self._minSup)
+        self._winLen = self._convert(self._winLen)
+        self._finalPatterns = {}
+        self._calculateOneLength()
+        self._generateSamePatterns(list(self._finalPatterns.keys()))
+        for x in list(self._finalPatterns.keys()):
+            for y in list(self._finalPatterns.keys()):
+                print(x, y)
+
+        self._endTime = _ab._time.time()
+        process = _ab._psutil.Process(_ab._os.getpid())
+        self._memoryUSS = float()
+        self._memoryRSS = float()
+        self._memoryUSS = process.memory_full_info().uss
+        self._memoryRSS = process.memory_info().rss
+        print("Frequent patterns were generated successfully using Apriori algorithm ")
+
+    def getMemoryUSS(self):
+        """Total amount of USS memory consumed by the mining process will be retrieved from this function
+
+        :return: returning USS memory consumed by the mining process
+
+        :rtype: float
+        """
+
+        return self._memoryUSS
+
+    def getMemoryRSS(self):
+        """Total amount of RSS memory consumed by the mining process will be retrieved from this function
+
+        :return: returning RSS memory consumed by the mining process
+
+        :rtype: float
+        """
+
+        return self._memoryRSS
+
+    def getRuntime(self):
+        """Calculating the total amount of runtime taken by the mining process
+
+        :return: returning total amount of runtime taken by the mining process
+
+        :rtype: float
+        """
+
+        return self._endTime - self._startTime
+
+    def getPatternsAsDataFrame(self):
+        """Storing final frequent patterns in a dataframe
+
+        :return: returning frequent patterns in a dataframe
+
+        :rtype: pd.DataFrame
+        """
+
+        dataFrame = {}
+        data = []
+        for a, b in self._finalPatterns.items():
+            data.append([a.replace('\t', ' '), b])
+            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
+        # dataFrame = dataFrame.replace(r'\r+|\n+|\t+',' ', regex=True)
+        return dataFrame
+
+    def save(self, outFile):
+        """Complete set of frequent patterns will be loaded in to a output file
+
+        :param outFile: name of the output file
+
+        :type outFile: file
+        """
+        self._oFile = outFile
+        writer = open(self._oFile, 'w+')
+        for x, y in self._finalPatterns.items():
+            s1 = x.strip() + ":" + str(y)
+            writer.write("%s \n" % s1)
+
+    def getPatterns(self):
+        """ Function to send the set of frequent patterns after completion of the mining process
+
+        :return: returning frequent patterns
+
+        :rtype: dict
+        """
+        return self._finalPatterns
+
+    def printResults(self):
+        print("Total number of Frequent Patterns:", len(self.getPatterns()))
+        print("Total Memory in USS:", self.getMemoryUSS())
+        print("Total Memory in RSS", self.getMemoryRSS())
+        print("Total ExecutionTime in ms:", self.getRuntime())
+
+
+if __name__ == "__main__":
+    _ap = str()
+    if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
+        if len(_ab._sys.argv) == 5:
+            _ap = Apriori(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+        if len(_ab._sys.argv) == 4:
+            _ap = Apriori(_ab._sys.argv[1], _ab._sys.argv[3])
+        _ap.startMine()
+        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save(_ab._sys.argv[2])
+        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
+    else:
+        _ap = Apriori('sample2.txt', 1, 3, ' ')
+        _ap.startMine()
+        for x, y in _ap.getPatterns().items():
+            print(x, y)
+        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save('output.txt')
+        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
+        print("Error! The number of input parameters do not match the total number of parameters provided")
+
Index: PAMI/episodeMining/MNEPIPlus.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/episodeMining/MNEPIPlus.py b/PAMI/episodeMining/MNEPIPlus.py
new file mode 100644
--- /dev/null	(date 1680660481657)
+++ b/PAMI/episodeMining/MNEPIPlus.py	(date 1680660481657)
@@ -0,0 +1,395 @@
+#  Copyright (C)  2021 Rage Uday Kiran
+#
+#      This program is free software: you can redistribute it and/or modify
+#      it under the terms of the GNU General Public License as published by
+#      the Free Software Foundation, either version 3 of the License, or
+#      (at your option) any later version.
+#
+#      This program is distributed in the hope that it will be useful,
+#      but WITHOUT ANY WARRANTY; without even the implied warranty of
+#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+#      GNU General Public License for more details.
+#
+#      You should have received a copy of the GNU General Public License
+#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+
+import abstract as _ab
+
+
+class MNEPIPlus(_ab._frequentEpisodes):
+    """
+        MNEPI++ is one of the fundamental algorithm to discover frequent episodes in a transactional database.
+        It is a depth-first search algorithm to find the frequent episodes using concepts lie equalJoin and temporalJoin.
+
+        Reference:
+        ----------
+            Kuo-Yu Huang, Chia-Hui Chang, Efficient mining of frequent episodes from complex sequences, Information Systems,
+            Volume 33, Issue 1, 2008, Pages 96-114, ISSN 0306-4379, https://doi.org/10.1016/j.is.2007.07.003.
+
+        Attributes:
+        ----------
+            iFile : str
+                Input file name or path of the input file
+            oFile : str
+                Name of the output file or the path of output file
+            minSup: float or int or str
+                The user can specify minSup either in count or proportion of database size.
+                If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+                Otherwise, it will be treated as float.
+                Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+            maxWin: int
+                The user can specify maxWin in count or proportion of database size.
+            sep : str
+                This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+                However, the users can override their default separator.
+            startTime:float
+                To record the start time of the mining process
+            endTime:float
+                To record the completion time of the mining process
+            finalPatterns: dict
+                Storing the complete set of patterns in a dictionary variable
+            memoryUSS : float
+                To store the total amount of USS memory consumed by the program
+            memoryRSS : float
+                To store the total amount of RSS memory consumed by the program
+            Database : list
+                To store the transactions of a database in list
+
+        Methods:
+        -------
+            startMine()
+                Mining process will start from here
+            getPatterns()
+                Complete set of patterns will be retrieved with this function
+            save(oFile)
+                Complete set of frequent patterns will be loaded in to a output file
+            getPatternsAsDataFrame()
+                Complete set of frequent patterns will be loaded in to a dataframe
+            getMemoryUSS()
+                Total amount of USS memory consumed by the mining process will be retrieved from this function
+            getMemoryRSS()
+                Total amount of RSS memory consumed by the mining process will be retrieved from this function
+            getRuntime()
+                Total amount of runtime taken by the mining process will be retrieved from this function
+            candidateToFrequent(candidateList)
+                Generates frequent patterns from the candidate patterns
+            frequentToCandidate(frequentList, length)
+                Generates candidate patterns from the frequent patterns
+
+
+        Executing the code on terminal:
+        -------------------------------
+
+            Format:
+            ------
+                python3 MNEPIPlus.py <inputFile> <outputFile> <minSup> <maxWin>
+
+            Examples:
+            ---------
+                python3 MNEPIPlus.py sampleDB.txt patterns.txt 10.0 3   (minSup will be considered in times of minSup and count of database transactions)
+
+                python3 MNEPIPlus.py sampleDB.txt patterns.txt 10 3    (minSup will be considered in support count or frequency)
+
+
+        Sample run of the importing code:
+        ---------------------------------
+
+            import PAMI.episodeMining.basic.MNEPIPlus as alg
+
+            obj = alg.MNEPIPlus(iFile, minSup)
+
+            obj.startMine()
+
+            frequentEpisodes = obj.getPatterns()
+
+            print("Total number of Frequent Patterns:", len(frequentEpisodes))
+
+            obj.save(oFile)
+
+            Df = obj.getPatternInDataFrame()
+
+            memUSS = obj.getMemoryUSS()
+
+            print("Total Memory in USS:", memUSS)
+
+            memRSS = obj.getMemoryRSS()
+
+            print("Total Memory in RSS", memRSS)
+
+            run = obj.getRuntime()
+
+            print("Total ExecutionTime in seconds:", run)
+
+        Credits:
+        --------
+            The complete program was written by P.Likhitha  under the supervision of Professor Rage Uday Kiran.
+
+    """
+
+    _minSup = float()
+    _winLen = int()
+    _startTime = float()
+    _endTime = float()
+    _finalPatterns = {}
+    _iFile = " "
+    _oFile = " "
+    _sep = " "
+    _memoryUSS = float()
+    _memoryRSS = float()
+    _Database = []
+    _tids = {}
+
+    def _creatingItemSets(self):
+        """
+            Storing the complete transactions of the database/input file in a database variable
+
+
+        """
+        self._Database = []
+        if isinstance(self._iFile, _ab._pd.DataFrame):
+            temp = []
+            if self._iFile.empty:
+                print("its empty..")
+            i = self._iFile.columns.values.tolist()
+            if 'Transactions' in i:
+                temp = self._iFile['Transactions'].tolist()
+
+            for k in temp:
+                self._Database.append(set(k))
+        if isinstance(self._iFile, str):
+            if _ab._validators.url(self._iFile):
+                data = _ab._urlopen(self._iFile)
+                for line in data:
+                    line.strip()
+                    line = line.decode("utf-8")
+                    temp = [i.rstrip() for i in line.split(self._sep)]
+                    temp = [x for x in temp if x]
+                    self._Database.append(set(temp))
+            else:
+                try:
+                    with open(self._iFile, 'r', encoding='utf-8') as f:
+                        for line in f:
+                            line.strip()
+                            temp = [i.rstrip() for i in line.split(self._sep)]
+                            temp = [x for x in temp if x]
+                            self._Database.append(temp)
+                except IOError:
+                    print("File Not Found")
+                    quit()
+
+    def _convert(self, value):
+        """
+        To convert the user specified minSup value
+
+        :param value: user specified minSup value
+
+        :return: converted type
+        """
+        if type(value) is int:
+            value = int(value)
+        if type(value) is float:
+            value = (len(self._Database) * value)
+        if type(value) is str:
+            if '.' in value:
+                value = float(value)
+                value = (len(self._Database) * value)
+            else:
+                value = int(value)
+        return value
+
+    def _calculateOneLength(self):
+        self._tids = {}
+        for i in self._Database:
+            for j in i[1:]:
+                if j not in self._tids:
+                    self._tids[j] = [[int(i[0]), int(i[0])]]
+                else:
+                    self._tids[j].append([int(i[0]), int(i[0])])
+        self._finalPatterns = {k: v for k, v in self._tids.items() if len(v) >= self._minSup}
+
+    def _calculateCount(self, tids):
+        count = 0
+        for i in tids:
+            if abs(i[0] - i[1]) <= self._winLen:
+                count += 1
+        return count
+
+    def _equalJoin(self, tidA, tidB):
+        res = []
+        for i in tidA:
+            if i in tidB:
+                res.append(i)
+        return res
+
+    def _temporalJoin(selfself, tidA, tidB):
+        tempList = []
+        ti = [set(i for j in tidA for i in j)]
+        tj = [set(i for j in tidB for i in j)]
+        print(ti, tj)
+
+    def _serialJoins(self, alpha, boundList, lastItem):
+        for i in self._tids.keys():
+            if i > lastItem:
+                tempBoundList = self._equalJoin(boundList, self._tids[i])
+                if self._calculateCount(tempBoundList) >= self._minSup:
+                    str = [alpha] + [i]
+                    self._serialJoins(str, tempBoundList, i)
+            tempBoundList = self._temporalJoin(boundList, self._tids[i])
+            if self._calculateCount(tempBoundList) >= self._minSup:
+                str = [alpha] + [i]
+                self._serialJoins(str, tempBoundList, i)
+
+    def _generateSamePatterns(self, candidateFrequent):
+        new_freqList = []
+        for i in range(0, len(candidateFrequent)):
+            item1 = candidateFrequent[i]
+            i1_list = item1.split()
+            for j in range(i + 1, len(candidateFrequent)):
+                item2 = candidateFrequent[j]
+                i2_list = item2.split()
+                if i1_list[:-1] == i2_list[:-1]:
+                    interSet = self._finalPatterns[item1].intersection(self._finalPatterns[item2])
+                    if len(interSet) >= self._minSup:
+                        newKey = item1 + "\t" + i2_list[-1]
+                        self._finalPatterns[newKey] = [interSet]
+                        new_freqList.append(newKey)
+                else:
+                    break
+
+        if len(new_freqList) > 0:
+            self._generateSamePatterns(new_freqList)
+
+    def _savePattern(self, prefix, suffix):
+        res = prefix + suffix
+        count = 0
+        for i in self._Database:
+                if set(res).issubset(i):
+                    count += 1
+        if count >= self._minSup:
+            self._finalPatterns[tuple(res)] = count
+
+    def startMine(self):
+        """
+            Frequent pattern mining process will start from here
+        """
+        self._Database = []
+        self._startTime = _ab._time.time()
+        self._creatingItemSets()
+        self._minSup = self._convert(self._minSup)
+        self._winLen = self._convert(self._winLen)
+        self._finalPatterns = {}
+        self._calculateOneLength()
+        #self._generateSamePatterns(list(self._finalPatterns.keys()))
+        for i in self._tids.keys():
+            self._serialJoins(i, self._tids[i], i)
+        # for x in list(self._finalPatterns.keys()):
+        #     for y in list(self._finalPatterns.keys()):
+        #         print(x, y)
+        self._endTime = _ab._time.time()
+        process = _ab._psutil.Process(_ab._os.getpid())
+        self._memoryUSS = float()
+        self._memoryRSS = float()
+        self._memoryUSS = process.memory_full_info().uss
+        self._memoryRSS = process.memory_info().rss
+        print("Frequent patterns were generated successfully using Apriori algorithm ")
+
+    def getMemoryUSS(self):
+        """Total amount of USS memory consumed by the mining process will be retrieved from this function
+
+        :return: returning USS memory consumed by the mining process
+
+        :rtype: float
+        """
+
+        return self._memoryUSS
+
+    def getMemoryRSS(self):
+        """Total amount of RSS memory consumed by the mining process will be retrieved from this function
+
+        :return: returning RSS memory consumed by the mining process
+
+        :rtype: float
+        """
+
+        return self._memoryRSS
+
+    def getRuntime(self):
+        """Calculating the total amount of runtime taken by the mining process
+
+        :return: returning total amount of runtime taken by the mining process
+
+        :rtype: float
+        """
+
+        return self._endTime - self._startTime
+
+    def getPatternsAsDataFrame(self):
+        """Storing final frequent patterns in a dataframe
+
+        :return: returning frequent patterns in a dataframe
+
+        :rtype: pd.DataFrame
+        """
+
+        dataFrame = {}
+        data = []
+        for a, b in self._finalPatterns.items():
+            data.append([a.replace('\t', ' '), b])
+            dataFrame = _ab._pd.DataFrame(data, columns=['Patterns', 'Support'])
+        # dataFrame = dataFrame.replace(r'\r+|\n+|\t+',' ', regex=True)
+        return dataFrame
+
+    def save(self, outFile):
+        """Complete set of frequent patterns will be loaded in to a output file
+
+        :param outFile: name of the output file
+
+        :type outFile: file
+        """
+        self._oFile = outFile
+        writer = open(self._oFile, 'w+')
+        for x, y in self._finalPatterns.items():
+            s1 = x.strip() + ":" + str(y)
+            writer.write("%s \n" % s1)
+
+    def getPatterns(self):
+        """ Function to send the set of frequent patterns after completion of the mining process
+
+        :return: returning frequent patterns
+
+        :rtype: dict
+        """
+        return self._finalPatterns
+
+    def printResults(self):
+        print("Total number of Frequent Patterns:", len(self.getPatterns()))
+        print("Total Memory in USS:", self.getMemoryUSS())
+        print("Total Memory in RSS", self.getMemoryRSS())
+        print("Total ExecutionTime in ms:", self.getRuntime())
+
+
+if __name__ == "__main__":
+    _ap = str()
+    if len(_ab._sys.argv) == 4 or len(_ab._sys.argv) == 5:
+        if len(_ab._sys.argv) == 5:
+            _ap = MNEPIPlus(_ab._sys.argv[1], _ab._sys.argv[3], _ab._sys.argv[4])
+        if len(_ab._sys.argv) == 4:
+            _ap = MNEPIPlus(_ab._sys.argv[1], _ab._sys.argv[3])
+        _ap.startMine()
+        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save(_ab._sys.argv[2])
+        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
+    else:
+        _ap = MNEPIPlus('sample2.txt', 1, 3, ' ')
+        _ap.startMine()
+        # for x, y in _ap.getPatterns().items():
+        #     print(x, y)
+        print("Total number of Frequent Patterns:", len(_ap.getPatterns()))
+        _ap.save('output.txt')
+        print("Total Memory in USS:", _ap.getMemoryUSS())
+        print("Total Memory in RSS", _ap.getMemoryRSS())
+        print("Total ExecutionTime in ms:", _ap.getRuntime())
+        print("Error! The number of input parameters do not match the total number of parameters provided")
+
Index: PAMI/episodeMining/abstract.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/PAMI/episodeMining/abstract.py b/PAMI/episodeMining/abstract.py
new file mode 100644
--- /dev/null	(date 1680660481672)
+++ b/PAMI/episodeMining/abstract.py	(date 1680660481672)
@@ -0,0 +1,168 @@
+#  Copyright (C)  2021 Rage Uday Kiran
+#
+#      This program is free software: you can redistribute it and/or modify
+#      it under the terms of the GNU General Public License as published by
+#      the Free Software Foundation, either version 3 of the License, or
+#      (at your option) any later version.
+#
+#      This program is distributed in the hope that it will be useful,
+#      but WITHOUT ANY WARRANTY; without even the implied warranty of
+#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+#      GNU General Public License for more details.
+#
+#      You should have received a copy of the GNU General Public License
+#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+#
+#      This program is free software: you can redistribute it and/or modify
+#      it under the terms of the GNU General Public License as published by
+#      the Free Software Foundation, either version 3 of the License, or
+#      (at your option) any later version.
+#
+#      This program is distributed in the hope that it will be useful,
+#      but WITHOUT ANY WARRANTY; without even the implied warranty of
+#      MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+#      GNU General Public License for more details.
+#
+#      You should have received a copy of the GNU General Public License
+#      along with this program.  If not, see <https://www.gnu.org/licenses/>.
+
+# from abc import ABC as _ABC, abstractmethod as _abstractmethod
+from abc import ABC as _ABC, abstractmethod as _abstractmethod
+import time as _time
+import csv as _csv
+import pandas as _pd
+from collections import defaultdict as _defaultdict
+from itertools import combinations as _c
+import os as _os
+import os.path as _ospath
+import psutil as _psutil
+import sys as _sys
+import validators as _validators
+from urllib.request import urlopen as _urlopen
+import functools as _functools
+
+
+class _frequentEpisodes(_ABC):
+    """ This abstract base class defines the variables and methods that every frequent pattern mining algorithm must
+        employ in PAMI
+
+
+       Attributes:
+       ----------
+        iFile : str
+            Input file name or path of the input file
+        minSup: integer or float or str
+            The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        sep : str
+            This variable is used to distinguish items from one another in a transaction. The default seperator is tab space or \t.
+            However, the users can override their default separator
+        startTime:float
+            To record the start time of the algorithm
+        endTime:float
+            To record the completion time of the algorithm
+        finalPatterns: dict
+            Storing the complete set of patterns in a dictionary variable
+        oFile : str
+            Name of the output file to store complete set of frequent patterns
+        memoryUSS : float
+            To store the total amount of USS memory consumed by the program
+        memoryRSS : float
+            To store the total amount of RSS memory consumed by the program
+
+       Methods:
+       -------
+        startMine()
+            Calling this function will start the actual mining process
+        getPatterns()
+            This function will output all interesting patterns discovered by an algorithm
+        save(oFile)
+            This function will store the discovered patterns in an output file specified by the user
+        getPatternsAsDataFrame()
+            The function outputs the patterns generated by an algorithm as a data frame
+        getMemoryUSS()
+            This function outputs the total amount of USS memory consumed by a mining algorithm
+        getMemoryRSS()
+            This function outputs the total amount of RSS memory consumed by a mining algorithm
+        getRuntime()
+            This function outputs the total runtime of a mining algorithm
+
+    """
+
+    def __init__(self, iFile, minSup, winLen, sep="\t"):
+        """
+        :param iFile: Input file name or path of the input file
+        :type iFile: str or DataFrame
+        :param minSup: The user can specify minSup either in count or proportion of database size.
+            If the program detects the data type of minSup is integer, then it treats minSup is expressed in count.
+            Otherwise, it will be treated as float.
+            Example: minSup=10 will be treated as integer, while minSup=10.0 will be treated as float
+        :type minSup: int or float or str
+        :param sep: separator used to distinguish items from each other. The default separator is tab space. However, users can override the default separator
+        :type sep: str
+        """
+
+        self._iFile = iFile
+        self._sep = sep
+        self._minSup = minSup
+        self._winLen = winLen
+        self._finalPatterns = {}
+        self._oFile = str()
+        self._memoryUSS = float()
+        self._memoryRSS = float()
+        self._startTime = float()
+        self._endTime = float()
+
+    @_abstractmethod
+    def startMine(self):
+        """Code for the mining process will start from this function"""
+
+        pass
+
+    @_abstractmethod
+    def getPatterns(self):
+        """Complete set of frequent patterns generated will be retrieved from this function"""
+
+        pass
+
+    @_abstractmethod
+    def save(self, oFile):
+        """Complete set of frequent patterns will be saved in to an output file from this function
+
+        :param oFile: Name of the output file
+        :type oFile: file
+        """
+
+        pass
+
+    @_abstractmethod
+    def getPatternsAsDataFrame(self):
+        """Complete set of frequent patterns will be loaded in to data frame from this function"""
+
+        pass
+
+    @_abstractmethod
+    def getMemoryUSS(self):
+        """Total amount of USS memory consumed by the program will be retrieved from this function"""
+
+        pass
+
+    @_abstractmethod
+    def getMemoryRSS(self):
+        """Total amount of RSS memory consumed by the program will be retrieved from this function"""
+
+        pass
+
+    @_abstractmethod
+    def getRuntime(self):
+        """Total amount of runtime taken by the program will be retrieved from this function"""
+
+        pass
+
+    @_abstractmethod
+    def printResults(self):
+        """ To print result of the execution"""
+
+        pass
\ No newline at end of file
diff --git a/PAMI/episodeMining/__init__.py b/PAMI/episodeMining/__init__.py
new file mode 100644
