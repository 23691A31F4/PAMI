{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be71095-de16-45c8-8f1b-847c53e44cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent patterns were generated successfully using frequentPatternGrowth algorithm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_521934/2522501603.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, pd.DataFrame({'algorithm': 'FPGrowth', 'minSup': minSupCount,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent patterns were generated successfully using frequentPatternGrowth algorithm\n",
      "Frequent patterns were generated successfully using frequentPatternGrowth algorithm\n",
      "Frequent patterns were generated successfully using frequentPatternGrowth algorithm\n",
      "Frequent patterns were generated successfully using frequentPatternGrowth algorithm\n",
      "  algorithm minSup patterns   runtime     memory\n",
      "0  FPGrowth    100    27517  7.604415  507404288\n",
      "1  FPGrowth    150    19119  7.653542  494821376\n",
      "2  FPGrowth    200    13252  7.533601  490008576\n",
      "3  FPGrowth    250     7679  7.193501  486580224\n",
      "4  FPGrowth    300     4540  7.146930  482967552\n"
     ]
    }
   ],
   "source": [
    "# Importing the required libraries\n",
    "from PAMI.frequentPattern.basic import FPGrowth as alg\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the input parameters\n",
    "inputFile = 'Transactional_T10I4D100K (2).csv'\n",
    "separator = '\\t'\n",
    "minimumSupportCountList = [100, 150, 200, 250, 300]\n",
    "\n",
    "# Initializing an empty DataFrame to store the results\n",
    "result = pd.DataFrame(columns=['algorithm', 'minSup', 'patterns', 'runtime', 'memory'])\n",
    "\n",
    "# Iterating over each minimum support count\n",
    "for minSupCount in minimumSupportCountList:\n",
    "    # Initializing the FPGrowth algorithm\n",
    "    obj = alg.FPGrowth(inputFile, minSup=minSupCount, sep=separator)\n",
    "    # Starting the mining process\n",
    "    obj.mine()\n",
    "    # Storing the results in the DataFrame\n",
    "    result = pd.concat([result, pd.DataFrame({'algorithm': 'FPGrowth', 'minSup': minSupCount, \n",
    "                                              'patterns': len(obj.getPatterns()), 'runtime': obj.getRuntime(), \n",
    "                                              'memory': obj.getMemoryRSS()}, index=[0])], ignore_index=True)\n",
    "\n",
    "# Printing the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f05690-b617-47fc-9e93-c3cb8607b125",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 33.59903335571289\n",
      "  algorithm  minSup  patterns   runtime     memory\n",
      "0  FPGrowth     100     27269  7.035575  760733696\n",
      "1  FPGrowth     150     19119  6.985118  745627648\n",
      "2  FPGrowth     200     13143  6.316768  738373632\n",
      "3  FPGrowth     250      7606  6.498432  731185152\n",
      "4  FPGrowth     300      4540  6.371540  725803008\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import psutil\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "# Read the dataset\n",
    "start_time_total = time.time()  # Start total runtime timer\n",
    "df = pd.read_csv('Transactional_T10I4D100K (2).csv', header=None)\n",
    "\n",
    "# Preprocess the dataset\n",
    "preprocessed_data = []\n",
    "for transaction in df[0]:\n",
    "    items = transaction.split('\\t')\n",
    "    preprocessed_data.append(items)\n",
    "\n",
    "# Encode the dataset\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit_transform(preprocessed_data)\n",
    "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Initialize a dataframe to store the results\n",
    "result = pd.DataFrame(columns=['algorithm', 'minSup', 'patterns', 'runtime', 'memory'])\n",
    "\n",
    "# Specify the minimum support count values\n",
    "minimumSupportCountList = [100, 150, 200, 250, 300]\n",
    "\n",
    "# Execute the algorithm at different minSup values\n",
    "for minSupCount in minimumSupportCountList:\n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Execute FPGrowth algorithm\n",
    "    frequent_itemsets = fpgrowth(df_encoded, min_support=minSupCount/len(df_encoded), use_colnames=True)\n",
    "    \n",
    "    # End timer\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate runtime\n",
    "    runtime = end_time - start_time\n",
    "    \n",
    "    # Measure memory usage\n",
    "    memory = psutil.Process().memory_info().rss\n",
    "    \n",
    "    # Append results for FPGrowth\n",
    "    result.loc[len(result)] = ['FPGrowth', minSupCount, frequent_itemsets.shape[0], runtime, memory]\n",
    "\n",
    "end_time_total = time.time()  # End total runtime timer\n",
    "total_runtime = end_time_total - start_time_total  # Calculate total runtime\n",
    "\n",
    "# Print the total runtime\n",
    "print(\"Total runtime:\", total_runtime)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff6608e0-7bf5-4d8e-87d9-e962ec3e2c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  algorithm  minSup  patterns   runtime     memory\n",
      "0  FPGrowth     100     27269  7.141550  760422400\n",
      "1  FPGrowth     150     19119  7.167196  747732992\n",
      "2  FPGrowth     200     13143  6.954512  738746368\n",
      "3  FPGrowth     250      7606  5.990916  731889664\n",
      "4  FPGrowth     300      4540  6.416880  725549056\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import psutil\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "# Initialize a dataframe to store the results\n",
    "result = pd.DataFrame(columns=['algorithm', 'minSup', 'patterns', 'runtime', 'memory'])\n",
    "\n",
    "# Specify the minimum support count values\n",
    "minimumSupportCountList = [100, 150, 200, 250, 300]\n",
    "\n",
    "# Execute the algorithm at different minSup values\n",
    "for minSupCount in minimumSupportCountList:\n",
    "    start_time_total = time.time()  # Start total runtime timer\n",
    "    \n",
    "    # Read the dataset\n",
    "    start_time_read = time.time()\n",
    "    df = pd.read_csv('Transactional_T10I4D100K (2).csv', header=None)\n",
    "    end_time_read = time.time()\n",
    "    \n",
    "    # Preprocess the dataset\n",
    "    start_time_pre = time.time()\n",
    "    preprocessed_data = []\n",
    "    for transaction in df[0]:\n",
    "        items = transaction.split('\\t')\n",
    "        preprocessed_data.append(items)\n",
    "    end_time_pre = time.time()\n",
    "    # Encode the dataset\n",
    "    start_time_te = time.time()\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit_transform(preprocessed_data)\n",
    "    df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    end_time_pre = time.time()\n",
    "    # Start timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Execute FPGrowth algorithm\n",
    "    frequent_itemsets = fpgrowth(df_encoded, min_support=minSupCount/len(df_encoded), use_colnames=True)\n",
    "    \n",
    "    # End timer\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate runtime for reading the dataset, preprocessing, and extracting patterns\n",
    "    total_runtime = end_time - start_time_total\n",
    "    \n",
    "    # Measure memory usage\n",
    "    memory = psutil.Process().memory_info().rss\n",
    "    \n",
    "    # Append results for FPGrowth\n",
    "    result.loc[len(result)] = ['FPGrowth', minSupCount, frequent_itemsets.shape[0], total_runtime, memory]\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db8ef910-dd8d-4644-b916-4306d220f2cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  algorithm  minSup  patterns   runtime     memory\n",
      "0  FPGrowth     100     27269  6.914114  760635392\n",
      "1  FPGrowth     150     19119  7.033635  747253760\n",
      "2  FPGrowth     200     13143  6.836374  740093952\n",
      "3  FPGrowth     250      7606  6.656244  731824128\n",
      "4  FPGrowth     300      4540  6.294214  726847488\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import psutil\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "# Initialize a dataframe to store the results\n",
    "result = pd.DataFrame(columns=['algorithm', 'minSup', 'patterns', 'runtime', 'memory'])\n",
    "\n",
    "# Specify the minimum support count values\n",
    "minimumSupportCountList = [100, 150, 200, 250, 300]\n",
    "\n",
    "# Execute the algorithm at different minSup values\n",
    "for minSupCount in minimumSupportCountList:\n",
    "    start_time_total = time.time()  # Start total runtime timer\n",
    "    \n",
    "    # Read the dataset\n",
    "    start_time_read = time.time()\n",
    "    df = pd.read_csv('Transactional_T10I4D100K (2).csv', header=None)\n",
    "    end_time_read = time.time()\n",
    "    read_time = end_time_read - start_time_read\n",
    "    \n",
    "    # Preprocess the dataset\n",
    "    start_time_pre = time.time()\n",
    "    preprocessed_data = []\n",
    "    for transaction in df[0]:\n",
    "        items = transaction.split('\\t')\n",
    "        preprocessed_data.append(items)\n",
    "    end_time_pre = time.time()\n",
    "    preprocess_time = end_time_pre - start_time_pre\n",
    "    \n",
    "    # Encode the dataset\n",
    "    start_time_te = time.time()\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit_transform(preprocessed_data)\n",
    "    df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    end_time_te = time.time()\n",
    "    encode_time = end_time_te - start_time_te\n",
    "    \n",
    "    # Start timer\n",
    "    start_time_alg = time.time()\n",
    "    \n",
    "    # Execute FPGrowth algorithm\n",
    "    frequent_itemsets = fpgrowth(df_encoded, min_support=minSupCount/len(df_encoded), use_colnames=True)\n",
    "    \n",
    "    # End timer\n",
    "    end_time_alg = time.time()\n",
    "    algorithm_time = end_time_alg - start_time_alg\n",
    "    \n",
    "    # Calculate total runtime\n",
    "    total_runtime = read_time + preprocess_time + encode_time + algorithm_time\n",
    "    \n",
    "    # Measure memory usage\n",
    "    memory = psutil.Process().memory_info().rss\n",
    "    \n",
    "    # Append results for FPGrowth\n",
    "    result.loc[len(result)] = ['FPGrowth', minSupCount, frequent_itemsets.shape[0], total_runtime, memory]\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d99357-7e49-4b4c-bc0a-663c07ff7ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  algorithm  minSup  patterns   runtime     memory\n",
      "0  FPGrowth     100     27269  7.320835  751087616\n",
      "1  FPGrowth     150     19119  6.632306  748331008\n",
      "2  FPGrowth     200     13143  6.937380  740073472\n",
      "3  FPGrowth     250      7606  6.525198  731832320\n",
      "4  FPGrowth     300      4540  6.097997  726028288\n",
      "Total Runtimes:\n",
      "MinSup: 100, Total Runtime: 7.3208 seconds\n",
      "MinSup: 150, Total Runtime: 6.6323 seconds\n",
      "MinSup: 200, Total Runtime: 6.9374 seconds\n",
      "MinSup: 250, Total Runtime: 6.5252 seconds\n",
      "MinSup: 300, Total Runtime: 6.0980 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import psutil\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "# Initialize a dataframe to store the results\n",
    "result = pd.DataFrame(columns=['algorithm', 'minSup', 'patterns', 'runtime', 'memory'])\n",
    "\n",
    "# Initialize a dictionary to store the total runtimes\n",
    "total_runtimes = {}\n",
    "\n",
    "# Specify the minimum support count values\n",
    "minimumSupportCountList = [100, 150, 200, 250, 300]\n",
    "\n",
    "# Execute the algorithm at different minSup values\n",
    "for minSupCount in minimumSupportCountList:\n",
    "    start_time_total = time.time()  # Start total runtime timer\n",
    "    \n",
    "    # Read the dataset\n",
    "    start_time_read = time.time()\n",
    "    df = pd.read_csv('Transactional_T10I4D100K (2).csv', header=None)\n",
    "    end_time_read = time.time()\n",
    "    read_time = end_time_read - start_time_read\n",
    "    \n",
    "    # Preprocess the dataset\n",
    "    start_time_pre = time.time()\n",
    "    preprocessed_data = []\n",
    "    for transaction in df[0]:\n",
    "        items = transaction.split('\\t')\n",
    "        preprocessed_data.append(items)\n",
    "    end_time_pre = time.time()\n",
    "    preprocess_time = end_time_pre - start_time_pre\n",
    "    \n",
    "    # Encode the dataset\n",
    "    start_time_te = time.time()\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit_transform(preprocessed_data)\n",
    "    df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    end_time_te = time.time()\n",
    "    encode_time = end_time_te - start_time_te\n",
    "    \n",
    "    # Start timer\n",
    "    start_time_alg = time.time()\n",
    "    \n",
    "    # Execute FPGrowth algorithm\n",
    "    frequent_itemsets = fpgrowth(df_encoded, min_support=minSupCount/len(df_encoded), use_colnames=True)\n",
    "    \n",
    "    # End timer\n",
    "    end_time_alg = time.time()\n",
    "    algorithm_time = end_time_alg - start_time_alg\n",
    "    \n",
    "    # Calculate total runtime\n",
    "    total_runtime = read_time + preprocess_time + encode_time + algorithm_time\n",
    "    \n",
    "    # Measure memory usage\n",
    "    memory = psutil.Process().memory_info().rss\n",
    "    \n",
    "    # Append results for FPGrowth\n",
    "    result.loc[len(result)] = ['FPGrowth', minSupCount, frequent_itemsets.shape[0], total_runtime, memory]\n",
    "    \n",
    "    # Store total runtime for this minSupCount\n",
    "    total_runtimes[minSupCount] = total_runtime\n",
    "\n",
    "# Print the result\n",
    "print(result)\n",
    "\n",
    "# Print the total runtimes at different minSup values\n",
    "print(\"Total Runtimes:\")\n",
    "for minSupCount, total_runtime in total_runtimes.items():\n",
    "    print(f\"MinSup: {minSupCount}, Total Runtime: {total_runtime:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2314a8df-a68c-4ac1-89af-40ce2fc3dbc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
